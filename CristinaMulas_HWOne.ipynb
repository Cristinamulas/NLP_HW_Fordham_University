{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CristinaMulas_HWOne.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cristinamulas/NLP_HW_Fordham_University/blob/master/CristinaMulas_HWOne.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFmun02sPPmR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Homework No. 1\n",
        "- CISC 6210 Natural Language \n",
        "- Date : 9/9/2020\n",
        "- Cristina Mulas "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwnPxGgtPKLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vFwYGQFcneO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1725940d-5531-41ea-bfcf-4e2c1b4823cd"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kXuRUFUJqZi",
        "colab_type": "text"
      },
      "source": [
        "## Part 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlr6ALMDJZQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "70b10ce0-b63c-4d7c-b91f-e94853cd4016"
      },
      "source": [
        "# import libraries\n",
        "import glob\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import string\n",
        "from nltk.stem import PorterStemmer\n",
        "stemming = PorterStemmer()\n",
        "import warnings\n",
        "from openpyxl.writer.excel import ExcelWriter\n",
        "from nltk.tokenize import TreebankWordTokenizer\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkNm4Xx9McNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reading_files (path):\n",
        "  \" it takes a file path and return a df with all the text files\"\n",
        "  df = pd.DataFrame() # create a df as a container\n",
        "  filelist = glob.glob(str(path)+'*.txt') \n",
        "\n",
        "  for f in  filelist: # loop over all the txt diles\n",
        "      read_file = pd.read_csv(f,delimiter = \"\\n\", encoding='latin-1', engine='python',header = None).transpose() # read the files and convert into rows\n",
        "\n",
        "      df = pd.concat([df,read_file],axis=0,ignore_index=True) # append all the dfs into one \n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK-Vvq-1ymtA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a6f9608-ba4c-4514-bb13-2f6c3b2c34d6"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtyCnE1dF6ry",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "b7c3280c-5674-452c-d54c-229db23d5c1e"
      },
      "source": [
        "!ls /content/drive/\"Shared drives\"/CISC6210NLPFall20/test/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 1979-ByRoddyLum.txt   Aperture-ByJenn.txt    fromTheRapeofLu.txt\n",
            " 66-BySuzanneGar.txt   Aphrodisia-ByRi.txt    FromtheSideline.txt\n",
            " 78RPM-ByJeffDan.txt   AphroditeMetrop.txt    fromTheSongofSo.txt\n",
            " ABalladTheLakeo.txt   APhysicsofDesir.txt    fromthewavethew.txt\n",
            " ABBA-ByDennisCo.txt   APityWeWereSuch.txt    fromToAlexisInA.txt\n",
            " ABC-ByKathrynMa.txt   APoemBeginningw.txt    fromToPriapusEl.txt\n",
            " ABirthday-ByChr.txt   APoemforPulse-B.txt   'fromTotemPoem[A.txt'\n",
            " AnOde-ByMatthew.txt  'APoemfortheh&aa.txt'  'fromTotemPoem[I.txt'\n",
            " AnOfferingforPa.txt   APoemfortheOldM.txt    fromTroilusandC.txt\n",
            " AnOld-Fashioned.txt   Apology-ByRubyR.txt   'FruitDon&rsquo;.txt'\n",
            " AnotherInsaneDe.txt   APornography-By.txt    Fruit-gathering.txt\n",
            " AnotherLullabyf.txt   APossumEntering.txt    FuckStuck-ByNao.txt\n",
            " AnotherMoon-ByZ.txt   FromtheNotebook.txt    FucktheAstronau.txt\n",
            " Antique-ByRober.txt   FromthePlane-By.txt    G-9-ByTimDlugos.txt\n",
            " Aoneendedboomer.txt   fromThePrincess.txt    GayPrideWeekend.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzMGXGm8bctM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "788f6af9-52ba-4e0d-f243-b8d63c0d7108"
      },
      "source": [
        "df = reading_files('/content/drive/Shared drives/CISC6210NLPFall20/LoveOutput/')\n",
        "#df = reading_files('/content/drive/Shared drives/CISC6210NLPFall20/test/')\n",
        "\n",
        "# df = reading_files('/content/gdrive/Shared drives/CISC6210NLPFall20/test/')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_next_iter_line\u001b[0;34m(self, row_num)\u001b[0m\n\u001b[1;32m   2890\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2891\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2892\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mError\u001b[0m: '\n' expected after '\"'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-e5aad762eda4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreading_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/Shared drives/CISC6210NLPFall20/LoveOutput/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#df = reading_files('/content/drive/Shared drives/CISC6210NLPFall20/test/')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# df = reading_files('/content/gdrive/Shared drives/CISC6210NLPFall20/test/')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-410e8398c476>\u001b[0m in \u001b[0;36mreading_files\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mfilelist\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# loop over all the txt diles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0mread_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# read the files and convert into rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# append all the dfs into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1124\u001b[0m                     \u001b[0;34m'\"python-fwf\")'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m                 )\n\u001b[0;32m-> 1126\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m   2311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_complex_date_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m             (index_names, self.orig_names, self.columns) = self._get_index_name(\n\u001b[0;32m-> 2313\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2314\u001b[0m             )\n\u001b[1;32m   2315\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_get_index_name\u001b[0;34m(self, columns)\u001b[0m\n\u001b[1;32m   3018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3019\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3020\u001b[0;31m             \u001b[0mnext_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3021\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0mnext_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_next_line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2831\u001b[0;31m                 \u001b[0morig_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_iter_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2832\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_next_iter_line\u001b[0;34m(self, row_num)\u001b[0m\n\u001b[1;32m   2912\u001b[0m                     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\". \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2914\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alert_malformed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2915\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_alert_malformed\u001b[0;34m(self, msg, row_num)\u001b[0m\n\u001b[1;32m   2870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_bad_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2872\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mParserError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2873\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_bad_lines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m             \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Skipping line {row_num}: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: '\n' expected after '\"'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtEdb87GMnB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.columns = ['Author_Title', 'Tags', 'Body', 'Link'] # name columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUnQNzQqbzx7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "6f62f156-7f59-4ae2-efe3-ffea56eced61"
      },
      "source": [
        "# cheching for null values\n",
        "df.isnull().sum()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Author_Title    0\n",
              "Tags            0\n",
              "Body            4\n",
              "Link            4\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhRMDqhBc7mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.dropna(subset=['Body', 'Link'], inplace = True) # removing all null values in features: Body, Link"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1ijFmb8daKD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "80c21c78-c2e4-443c-fa44-224aa795a49c"
      },
      "source": [
        "# cheching for null values\n",
        "\n",
        "df.isnull().sum()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Author_Title    0\n",
              "Tags            0\n",
              "Body            0\n",
              "Link            0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyVx4VN68m1M",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "### Create a new features for Autor and Titte\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPXuaAN3dB8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Author'] = df['Author_Title'].apply(lambda x :x.split('By')[1]) # create an Author col by spliting Author_Title column\n",
        "df['Title'] = df['Author_Title'].apply(lambda x :x.split('By')[0]) # create a Title col by spliting Author_Title column\n",
        "df.drop(['Author_Title'], axis = 1, inplace = True) # delete Author_Title col from df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KWWMkZRg-tc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "e143ecb3-6407-4372-e398-07315cd21170"
      },
      "source": [
        "df.info() # checking"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 41 entries, 0 to 44\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Tags    41 non-null     object\n",
            " 1   Body    41 non-null     object\n",
            " 2   Link    41 non-null     object\n",
            " 3   Author  41 non-null     object\n",
            " 4   Title   41 non-null     object\n",
            "dtypes: object(5)\n",
            "memory usage: 1.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krTrWNJ086hQ",
        "colab_type": "text"
      },
      "source": [
        "### Cleaning Body Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlEWgqpOOMWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removing encoding charcteres in all the rows\n",
        "df['Body'] = df['Body'].apply(lambda x : str(x).encode(\"ascii\", \"ignore\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsyGvy9j3UI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Body'] = df['Body'].apply(lambda x: str(x).replace('<br><br>','[P]')) # replace line breaks by [L]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mokVqgKN4KmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Body'] = df['Body'].apply(lambda x: str(x).replace('<br>','[L]')) # replace paragraph breaks by [L]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Cw0UF2R4PQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Body'] = df['Body'].apply(lambda x: re.sub('<.*?>', '', str(x))) # removing all the tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6GH9HYlUV9a",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "### Cleaning Link Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxwOZjm75G66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Link'] = df['Link'].apply(lambda x : re.sub(r'original link:', '', str(x))) # return only the URL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJn_nC1M5QvG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "dc3bac9a-824a-4b3d-a051-a379f7b1a45c"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tags      0\n",
              "Body      0\n",
              "Link      0\n",
              "Author    0\n",
              "Title     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfyWt-1KiUtP",
        "colab_type": "text"
      },
      "source": [
        "### Questions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMrjDQavK670",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "a73991cd-8e90-4883-a267-1d623af40fed"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tags</th>\n",
              "      <th>Body</th>\n",
              "      <th>Link</th>\n",
              "      <th>Author</th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Living ;Life Choices ;Time &amp; Brevity ;Love ;De...</td>\n",
              "      <td>b'They arrived at the desk of the Hotel Duncan...</td>\n",
              "      <td>https://www.poetryfoundation.org/poetrymagazi...</td>\n",
              "      <td>Roddy Lumsden</td>\n",
              "      <td>1979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Living ;Love ;Classic Love ;Desire ;Infatuatio...</td>\n",
              "      <td>b\"My heart is like a singing bird [L]Whose nes...</td>\n",
              "      <td>https://www.poetryfoundation.org/poems/44992/...</td>\n",
              "      <td>Christina Rossetti</td>\n",
              "      <td>A Birthday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Love ;Relationships ;Family &amp; Ancestors ;Men &amp;...</td>\n",
              "      <td>b'In the back of the junkhouse [L]stacked on a...</td>\n",
              "      <td>https://www.poetryfoundation.org/poems/53524/...</td>\n",
              "      <td>Jeff Daniel Marion</td>\n",
              "      <td>78 RPM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Living ;Coming of Age ;Love ;Unrequited Love ;...</td>\n",
              "      <td>b'                                            ...</td>\n",
              "      <td>https://www.poetryfoundation.org/poems/54885/...</td>\n",
              "      <td>Dennis Cooper</td>\n",
              "      <td>ABBA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Living ;Health &amp; Illness ;Life Choices ;The Mi...</td>\n",
              "      <td>b'                                            ...</td>\n",
              "      <td>https://www.poetryfoundation.org/poetrymagazi...</td>\n",
              "      <td>Kathryn Maris</td>\n",
              "      <td>ABC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Tags  ...        Title\n",
              "0  Living ;Life Choices ;Time & Brevity ;Love ;De...  ...        1979 \n",
              "1  Living ;Love ;Classic Love ;Desire ;Infatuatio...  ...  A Birthday \n",
              "2  Love ;Relationships ;Family & Ancestors ;Men &...  ...      78 RPM \n",
              "3  Living ;Coming of Age ;Love ;Unrequited Love ;...  ...        ABBA \n",
              "4  Living ;Health & Illness ;Life Choices ;The Mi...  ...         ABC \n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-GRzGc7sccn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3f60e93-b8af-4da2-abc0-d4483b2e8ae8"
      },
      "source": [
        "# total number of poems stored\n",
        "len(df['Body'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-RMVWyPsprp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f99df126-91ee-4f85-f8bb-1efafe6fa147"
      },
      "source": [
        "# number of authots\n",
        "df['Author'].value_counts().count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0jetekpsu8g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "7f463769-c64d-4fa8-9264-a96dbde70f8a"
      },
      "source": [
        "# sort authors by the amount of their poems collected in the table, and show top 20 authors. \n",
        "df['Author'].value_counts()[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " Luke Davies                     2\n",
              " Anne Marie Macari               1\n",
              " Aphra Behn                      1\n",
              " Jeff Daniel Marion              1\n",
              " Samuel Wagan Watson             1\n",
              " Rabindranath Tagore             1\n",
              " Richard Hoffman                 1\n",
              " Robert Pinsky                   1\n",
              " Rosanna Warren                  1\n",
              " Roddy Lumsden                   1\n",
              " Tibullus                        1\n",
              " Jameson Fitzpatrick             1\n",
              " A. E. Stallings                 1\n",
              " Tom Healy                       1\n",
              " Brenda Shaughnessy              1\n",
              " Robert Duncan                   1\n",
              " Yehuda Amichai                  1\n",
              " Elsa von Freytag-Loringhoven    1\n",
              " Alfred, Lord Tennyson           1\n",
              " John Wieners                    1\n",
              "Name: Author, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3OhAi7YtZNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save in a excell file without null values\n",
        "df.to_excel('CleanOutputLoveOutput.xlsx', index=False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ-8s0DGj5LF",
        "colab_type": "text"
      },
      "source": [
        "## Part 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNv-R_JSuU0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_clean = pd.read_excel('CleanOutputLoveOutput.xlsx')  # reading the excell file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt30BIxvuf36",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "ed21d3b8-9ace-47f7-9d1e-b044c7ad3440"
      },
      "source": [
        "df_clean.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tags</th>\n",
              "      <th>Body</th>\n",
              "      <th>Link</th>\n",
              "      <th>Author</th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Living ;Life Choices ;Time &amp; Brevity ;Love ;De...</td>\n",
              "      <td>b'They arrived at the desk of the Hotel Duncan...</td>\n",
              "      <td>https://www.poetryfoundation.org/poetrymagazi...</td>\n",
              "      <td>Roddy Lumsden</td>\n",
              "      <td>1979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Living ;Love ;Classic Love ;Desire ;Infatuatio...</td>\n",
              "      <td>b\"My heart is like a singing bird [L]Whose nes...</td>\n",
              "      <td>https://www.poetryfoundation.org/poems/44992/...</td>\n",
              "      <td>Christina Rossetti</td>\n",
              "      <td>A Birthday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Love ;Relationships ;Family &amp; Ancestors ;Men &amp;...</td>\n",
              "      <td>b'In the back of the junkhouse [L]stacked on a...</td>\n",
              "      <td>https://www.poetryfoundation.org/poems/53524/...</td>\n",
              "      <td>Jeff Daniel Marion</td>\n",
              "      <td>78 RPM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Living ;Coming of Age ;Love ;Unrequited Love ;...</td>\n",
              "      <td>b'                                            ...</td>\n",
              "      <td>https://www.poetryfoundation.org/poems/54885/...</td>\n",
              "      <td>Dennis Cooper</td>\n",
              "      <td>ABBA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Living ;Health &amp; Illness ;Life Choices ;The Mi...</td>\n",
              "      <td>b'                                            ...</td>\n",
              "      <td>https://www.poetryfoundation.org/poetrymagazi...</td>\n",
              "      <td>Kathryn Maris</td>\n",
              "      <td>ABC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Tags  ...        Title\n",
              "0  Living ;Life Choices ;Time & Brevity ;Love ;De...  ...        1979 \n",
              "1  Living ;Love ;Classic Love ;Desire ;Infatuatio...  ...  A Birthday \n",
              "2  Love ;Relationships ;Family & Ancestors ;Men &...  ...      78 RPM \n",
              "3  Living ;Coming of Age ;Love ;Unrequited Love ;...  ...        ABBA \n",
              "4  Living ;Health & Illness ;Life Choices ;The Mi...  ...         ABC \n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixRKnTlJT-8i",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "### Create PoemID Feature\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btl_GusYjr0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create PoemID feature\n",
        "df_clean['PoemID'] = pd.Series(range(1,2043))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ1IVNjLVX6F",
        "colab_type": "text"
      },
      "source": [
        "### Create NumPara Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaV3GQKWft8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_clean['NumPara'] = df_clean['Body'].apply(lambda x: str(x).count(\"[P]\")) # create a new feature with the count of a para"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1rh_85VVS_j",
        "colab_type": "text"
      },
      "source": [
        "### Create NumLine Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqNSpM5HdZvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_clean['line_breaks'] = df_clean['Body'].apply(lambda x: str(x).count(\"[L]\")) #create a new feature with the count of new lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HZeixBIgiPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_clean[\"NumLine\"] = df_clean['line_breaks'] + df_clean['NumPara'] # create a new feature with the sum of the line breaks and para"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4sTblHVcs1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove [P] symbols \n",
        "df_clean['Body'] = df_clean['Body'].apply(lambda x : x.replace('[P]', ''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ma-YiWQcsh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove [L] symbols \n",
        "df_clean['Body'] = df_clean['Body'].apply(lambda x : x.replace('[L]', ''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouxAFk11Ub11",
        "colab_type": "text"
      },
      "source": [
        "### Create LengthOne Feaure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbTfgOlkWUJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokens_wo_punctuation(text):\n",
        "  \"\"\"it takes an str and return the lenght of the tokens w/o punctuation\"\"\"\n",
        "  tokens = TreebankWordTokenizer().tokenize(text)\n",
        "  token_words = [w for w in tokens if w.isalpha()]\n",
        "  return len(token_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yse1TCo3fLPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df_clean['LengthOne']= df_clean['Body'].apply(lambda x :tokens_wo_punctuation(x)) # create a new feature with the len of the tokens w/o punctuation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj4_Fy5cU2Hn",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "### Create LengthTwo Feaure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGxjJUJOXiiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_clean['LenthTwo'] = df_clean['Body'].apply(lambda x: len(TreebankWordTokenizer().tokenize(x)))# create a new feature with the len of the tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-pW1dM8VtPH",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "### Create NumLSent Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCLbSzvGgs1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_clean['NumSent'] = df_clean['Body'].apply(lambda x : len(nltk.tokenize.sent_tokenize(x))) # create a feature with the number of sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pBSLmvHWQAK",
        "colab_type": "text"
      },
      "source": [
        "### Create NumComma Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV0mkyYQjmFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_clean['NumComma'] = df_clean['Body'].apply(lambda x : str(x).count(\",\")) # createa new feature with the total nulber of commas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XnYEAicWj0P",
        "colab_type": "text"
      },
      "source": [
        "### Create a new df "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jts3huNhaHad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_stats = df_clean.copy() # make a copy of the df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWLAIfqyknUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_stats_final = df_stats[['Author', 'PoemID', 'LengthOne' , 'LenthTwo', 'NumPara', 'NumLine', 'NumSent','NumComma']] # subseting features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HxshnbtYJoj",
        "colab_type": "text"
      },
      "source": [
        "### Show statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGzPa-VPXfZM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "9edda498-48a4-4833-fc54-4a6193f48715"
      },
      "source": [
        "df_stats_final.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PoemID</th>\n",
              "      <th>LengthOne</th>\n",
              "      <th>LenthTwo</th>\n",
              "      <th>NumPara</th>\n",
              "      <th>NumLine</th>\n",
              "      <th>NumSent</th>\n",
              "      <th>NumComma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>41.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>41.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>21.000000</td>\n",
              "      <td>327.902439</td>\n",
              "      <td>390.951220</td>\n",
              "      <td>6.804878</td>\n",
              "      <td>55.731707</td>\n",
              "      <td>17.756098</td>\n",
              "      <td>27.926829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>11.979149</td>\n",
              "      <td>481.180777</td>\n",
              "      <td>575.295009</td>\n",
              "      <td>11.948262</td>\n",
              "      <td>103.195209</td>\n",
              "      <td>32.454415</td>\n",
              "      <td>39.447681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>21.000000</td>\n",
              "      <td>177.000000</td>\n",
              "      <td>210.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>31.000000</td>\n",
              "      <td>319.000000</td>\n",
              "      <td>358.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>30.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>41.000000</td>\n",
              "      <td>2891.000000</td>\n",
              "      <td>3445.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>637.000000</td>\n",
              "      <td>194.000000</td>\n",
              "      <td>218.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          PoemID    LengthOne     LenthTwo  ...     NumLine     NumSent    NumComma\n",
              "count  41.000000    41.000000    41.000000  ...   41.000000   41.000000   41.000000\n",
              "mean   21.000000   327.902439   390.951220  ...   55.731707   17.756098   27.926829\n",
              "std    11.979149   481.180777   575.295009  ...  103.195209   32.454415   39.447681\n",
              "min     1.000000    40.000000    46.000000  ...    5.000000    1.000000    0.000000\n",
              "25%    11.000000   110.000000   123.000000  ...   16.000000    2.000000    6.000000\n",
              "50%    21.000000   177.000000   210.000000  ...   24.000000    8.000000   14.000000\n",
              "75%    31.000000   319.000000   358.000000  ...   49.000000   17.000000   30.000000\n",
              "max    41.000000  2891.000000  3445.000000  ...  637.000000  194.000000  218.000000\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY4x1a-XcWp8",
        "colab_type": "text"
      },
      "source": [
        "## Part 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSzHg51xZMle",
        "colab_type": "text"
      },
      "source": [
        "### Tokenize DataFrame\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07xI5f_UXqTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new df\n",
        "df_token = df_clean.copy() # make a copy of the df\n",
        "df_tokenize = df_token[['PoemID', 'Author',  'Body']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r4w6_57etjA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "c49a9489-2186-4eed-c9dc-624dda0c5da8"
      },
      "source": [
        "df_tokenize['Body'] = df_tokenize['Body'].apply(lambda x: TreebankWordTokenizer().tokenize(x)) # tokenize the body feature\n",
        "df_tokenize['Lenght'] = df_tokenize['Body'].apply(lambda x: len(x)) # create lenght feature\n",
        "df_tokenize['UniCount'] = df_tokenize['Body'].apply(lambda x: len(set(x))) # create vocabulary size feautre\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE3I5ZiW-pj5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "2dd9af78-cb56-4709-e4f5-90c09e10902a"
      },
      "source": [
        "df_tokenize.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PoemID</th>\n",
              "      <th>Author</th>\n",
              "      <th>Body</th>\n",
              "      <th>Lenght</th>\n",
              "      <th>UniCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Roddy Lumsden</td>\n",
              "      <td>[b'They, arrived, at, the, desk, of, the, Hote...</td>\n",
              "      <td>288</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Christina Rossetti</td>\n",
              "      <td>[b, '', My, heart, is, like, a, singing, bird,...</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Jeff Daniel Marion</td>\n",
              "      <td>[b'In, the, back, of, the, junkhouse, stacked,...</td>\n",
              "      <td>97</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Dennis Cooper</td>\n",
              "      <td>[b, ', for, Brad, Gooch, We, snort, all, our, ...</td>\n",
              "      <td>171</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Kathryn Maris</td>\n",
              "      <td>[b, ', Identification, is, a, highly, importan...</td>\n",
              "      <td>324</td>\n",
              "      <td>172</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PoemID               Author  ... Lenght  UniCount\n",
              "0       1        Roddy Lumsden  ...    288       187\n",
              "1       2   Christina Rossetti  ...    121        72\n",
              "2       3   Jeff Daniel Marion  ...     97        68\n",
              "3       4        Dennis Cooper  ...    171       113\n",
              "4       5        Kathryn Maris  ...    324       172\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pr0fz4ZuZCf",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        " ### Stop Words DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP9FYCstcNPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_s_w = df_clean.copy() # make a copy of the df\n",
        "df_stop_words = df_s_w[['PoemID', 'Author',  'Body']]  # subseting col"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeHwuUUQcNY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stop_words(text):\n",
        "  \" it takes an str return a list of tokenize w/o stop words\"\n",
        "  tokens = TreebankWordTokenizer().tokenize(text)\n",
        "  tokens_without_sw = [word for word in tokens if not word in stopwords.words('english')]\n",
        "  return tokens_without_sw "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtfXhPe2ZsA4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "29705f66-9b95-46e6-b26d-4ab1fa15c682"
      },
      "source": [
        "df_stop_words['Body'] = df_stop_words['Body'].apply(lambda x : remove_stop_words(x)) # tokenize the body feature with stop word removal\n",
        "df_stop_words['Lenght'] = df_stop_words['Body'].apply(lambda x : len(x)) # create lenght feature\n",
        "df_stop_words['UniCount'] = df_stop_words['Body'].apply(lambda x : len(set(x))) # create vocabulary size feautre"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1r3Jkkv_Tb3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "a57a73a5-be4b-4883-9a35-163a6f317449"
      },
      "source": [
        "df_stop_words.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PoemID</th>\n",
              "      <th>Author</th>\n",
              "      <th>Body</th>\n",
              "      <th>Lenght</th>\n",
              "      <th>UniCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Roddy Lumsden</td>\n",
              "      <td>[b'They, arrived, desk, Hotel, Duncanand, Smit...</td>\n",
              "      <td>159</td>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Christina Rossetti</td>\n",
              "      <td>[b, '', My, heart, like, singing, bird, Whose,...</td>\n",
              "      <td>78</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Jeff Daniel Marion</td>\n",
              "      <td>[b'In, back, junkhouse, stacked, cardtable, co...</td>\n",
              "      <td>60</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Dennis Cooper</td>\n",
              "      <td>[b, ', Brad, Gooch, We, snort, coke, way, part...</td>\n",
              "      <td>107</td>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Kathryn Maris</td>\n",
              "      <td>[b, ', Identification, highly, important, fact...</td>\n",
              "      <td>189</td>\n",
              "      <td>128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PoemID               Author  ... Lenght  UniCount\n",
              "0       1        Roddy Lumsden  ...    159       138\n",
              "1       2   Christina Rossetti  ...     78        55\n",
              "2       3   Jeff Daniel Marion  ...     60        50\n",
              "3       4        Dennis Cooper  ...    107        81\n",
              "4       5        Kathryn Maris  ...    189       128\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqx8pqcdyK6a",
        "colab_type": "text"
      },
      "source": [
        "### Stop Words Stemming DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbf7yL6yya1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_st = df_clean.copy() # make a copy of the df\n",
        "df_stemming = df_st[['PoemID', 'Author',  'Body']] # subseting col"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aePKud44Xur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def remove_stop_words_stem(text):\n",
        "  \" it takes an str return a list of tokenize w/o stop words and stemming\"\n",
        "  tokens = TreebankWordTokenizer().tokenize(text)\n",
        "  tokens_without_sw_stem = [stemming.stem(word) for word in tokens if not word in stopwords.words('english')]\n",
        "  return tokens_without_sw_stem\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A-_CXQtylH_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "67fd0018-915e-4e09-e36f-70d5f24e9ea6"
      },
      "source": [
        "df_stemming['Body'] = df_stemming['Body'].apply(lambda x :remove_stop_words_stem(x)) # tokenize the body feature with stop words removal and stemming\n",
        "df_stemming['Lenght'] = df_stemming['Body'].apply(lambda x : len((x))) # create lenght feature\n",
        "df_stemming['UniCount'] = df_stemming['Body'].apply(lambda x : len(set(x))) # create vocabulary size feautre"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6ZmBijyAFBc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "905000ea-a4cc-4888-e74d-e5397f18eb39"
      },
      "source": [
        "df_stemming.head() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PoemID</th>\n",
              "      <th>Author</th>\n",
              "      <th>Body</th>\n",
              "      <th>Lenght</th>\n",
              "      <th>UniCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Roddy Lumsden</td>\n",
              "      <td>[b'they, arriv, desk, hotel, duncanand, smith,...</td>\n",
              "      <td>159</td>\n",
              "      <td>136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Christina Rossetti</td>\n",
              "      <td>[b, '', My, heart, like, sing, bird, whose, ne...</td>\n",
              "      <td>78</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Jeff Daniel Marion</td>\n",
              "      <td>[b'in, back, junkhous, stack, cardtabl, cover,...</td>\n",
              "      <td>60</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Dennis Cooper</td>\n",
              "      <td>[b, ', brad, gooch, We, snort, coke, way, part...</td>\n",
              "      <td>107</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Kathryn Maris</td>\n",
              "      <td>[b, ', identif, highli, import, factor, mechan...</td>\n",
              "      <td>189</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PoemID               Author  ... Lenght  UniCount\n",
              "0       1        Roddy Lumsden  ...    159       136\n",
              "1       2   Christina Rossetti  ...     78        55\n",
              "2       3   Jeff Daniel Marion  ...     60        50\n",
              "3       4        Dennis Cooper  ...    107        80\n",
              "4       5        Kathryn Maris  ...    189       123\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANmhZqePa_yg",
        "colab_type": "text"
      },
      "source": [
        "### Save it in excell file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN1N5qadk8H7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_dfs_excel(dfs):\n",
        "  \" it takes a list of dfs and retunr a excell file with 4 sheets\"\n",
        "\n",
        "  writer = pd.ExcelWriter('outputProcessedLoveOutput.xlsx')\n",
        "  for i, u in enumerate(dfs): # loop over the index and the dfs\n",
        "    u.to_excel(writer, f'sheet{i}')\n",
        "  return writer.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ9sl8GnmoxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_list = [df_stats_final ,df_tokenize, df_stop_words, df_stemming]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJBMFBq1m50E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_dfs_excel(df_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne3WNGKAzCHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bTAHLFtzEfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}